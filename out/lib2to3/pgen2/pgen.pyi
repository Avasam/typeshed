from . import grammar as grammar, token as token, tokenize as tokenize
from _typeshed import Incomplete

class PgenGrammar(grammar.Grammar): ...

class ParserGenerator:
    filename: Incomplete
    stream: Incomplete
    generator: Incomplete
    first: Incomplete
    def __init__(self, filename, stream: Incomplete | None = ...) -> None: ...
    def make_grammar(self): ...
    def make_first(self, c, name): ...
    def make_label(self, c, label): ...
    def addfirstsets(self) -> None: ...
    def calcfirst(self, name) -> None: ...
    def parse(self): ...
    def make_dfa(self, start, finish): ...
    def dump_nfa(self, name, start, finish) -> None: ...
    def dump_dfa(self, name, dfa) -> None: ...
    def simplify_dfa(self, dfa) -> None: ...
    def parse_rhs(self): ...
    def parse_alt(self): ...
    def parse_item(self): ...
    def parse_atom(self): ...
    def expect(self, type, value: Incomplete | None = ...): ...
    def gettoken(self) -> None: ...
    def raise_error(self, msg, *args) -> None: ...

class NFAState:
    arcs: Incomplete
    def __init__(self) -> None: ...
    def addarc(self, next, label: Incomplete | None = ...) -> None: ...

class DFAState:
    nfaset: Incomplete
    isfinal: Incomplete
    arcs: Incomplete
    def __init__(self, nfaset, final) -> None: ...
    def addarc(self, next, label) -> None: ...
    def unifystate(self, old, new) -> None: ...
    def __eq__(self, other): ...
    __hash__: Incomplete

def generate_grammar(filename: str = ...): ...
